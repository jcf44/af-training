# PPE Detection - Jetson Orin Nano Configuration
# INT8 optimized for edge performance

[property]
gpu-id=0
net-scale-factor=0.0039215697906911373

# Model files
onnx-file=/app/models/ppe_best.onnx
model-engine-file=/app/engines/ppe_best_orin_int8.engine

# Labels
labelfile-path=/app/labels/ppe.txt

# INT8 calibration
int8-calib-file=/app/calibration/CalibrationTable

# Inference settings
batch-size=1
process-mode=1
model-color-format=0
network-mode=1

# YOLO specific
num-detected-classes=6
cluster-mode=2
parse-bbox-func-name=NvDsInferParseYolo
custom-lib-path=/opt/nvidia/deepstream/deepstream/lib/libnvds_infercustomparser.so

interval=0
gie-unique-id=1
network-type=0

[class-attrs-all]
nms-iou-threshold=0.45
pre-cluster-threshold=0.25
topk=300
